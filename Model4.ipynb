{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9bcae6",
   "metadata": {},
   "source": [
    "Model 4:\n",
    "Target\n",
    "1. Add LR Scheduler \n",
    "2. Try Differnet optimizer (Adam)\n",
    "3. Add Data Augmentation\n",
    "\n",
    "Result:\n",
    "1. Parameters : 8024\n",
    "2. Best Train Accuracy : 99.30\n",
    "3. Best Test Accuracy : 99.41\n",
    "\n",
    "Analysis\n",
    "1. The train and test accuracy increased after adding LR scheduler\n",
    "2. Accuracy with SGD was 99.35 and improved upon using Adam optimizer. \n",
    "2. Addition of data augmentation, reduced initial accuracy but accuracy increased in later epochs. But the test accuracy hovered around 99.38-39\n",
    "3. Little bit reduction of parameters was bringing down accuracy to around 99.38 so went ahead with 8024 parameters\n",
    "4. The model is still underfitting as training accuracy has been increasing steadily over epochs and its less than test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdba922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02c9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    #transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7379af43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4459091.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 154429.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1232255.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 3764182.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473c1675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "#train_loader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "#test_loader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a993f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_value = 0.1\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    #INPUT\n",
    "    self.conv1= nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(8),\n",
    "        nn.Dropout(dropout_value)\n",
    "    )#output = 26\n",
    "\n",
    "    #CONV 1 BLOCK\n",
    "    self.conv2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.Dropout(dropout_value)\n",
    "    )#output = 24\n",
    "\n",
    "    #TRANSITION BLOCK\n",
    "    self.conv3 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1,1), padding=0, bias=False),\n",
    "    )#output = 24\n",
    "\n",
    "    self.pool1 = nn.MaxPool2d(2,2)\n",
    "    #output = 12\n",
    "\n",
    "    #CONV 2 BLOCK\n",
    "    self.conv4 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.Dropout(dropout_value)\n",
    "    )#output = 10\n",
    "\n",
    "\n",
    "    self.conv5 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.Dropout(dropout_value)\n",
    "    )#output = 8\n",
    "\n",
    "    self.conv6 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.Dropout(dropout_value)\n",
    "    )#output = 6\n",
    "\n",
    "\n",
    "    self.conv7 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(1,1), padding=1, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.Dropout(dropout_value)\n",
    "    )#output = 6\n",
    "\n",
    "    #OUTPUT BLOCK\n",
    "    self.gap = nn.Sequential(\n",
    "         nn.AvgPool2d(kernel_size=6)\n",
    "    )#output = 1\n",
    "\n",
    "    self.conv8 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.pool1(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.conv5(x)\n",
    "    x = self.conv6(x)\n",
    "    x = self.conv7(x)\n",
    "    x = self.gap(x)\n",
    "    x = self.conv8(x)\n",
    "    x = x.view(-1,10)\n",
    "    return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e5f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]              72\n",
      "              ReLU-2            [-1, 8, 26, 26]               0\n",
      "       BatchNorm2d-3            [-1, 8, 26, 26]              16\n",
      "           Dropout-4            [-1, 8, 26, 26]               0\n",
      "            Conv2d-5           [-1, 16, 24, 24]           1,152\n",
      "              ReLU-6           [-1, 16, 24, 24]               0\n",
      "       BatchNorm2d-7           [-1, 16, 24, 24]              32\n",
      "           Dropout-8           [-1, 16, 24, 24]               0\n",
      "            Conv2d-9           [-1, 10, 24, 24]             160\n",
      "        MaxPool2d-10           [-1, 10, 12, 12]               0\n",
      "           Conv2d-11           [-1, 16, 10, 10]           1,440\n",
      "             ReLU-12           [-1, 16, 10, 10]               0\n",
      "      BatchNorm2d-13           [-1, 16, 10, 10]              32\n",
      "          Dropout-14           [-1, 16, 10, 10]               0\n",
      "           Conv2d-15             [-1, 16, 8, 8]           2,304\n",
      "             ReLU-16             [-1, 16, 8, 8]               0\n",
      "      BatchNorm2d-17             [-1, 16, 8, 8]              32\n",
      "          Dropout-18             [-1, 16, 8, 8]               0\n",
      "           Conv2d-19             [-1, 16, 6, 6]           2,304\n",
      "             ReLU-20             [-1, 16, 6, 6]               0\n",
      "      BatchNorm2d-21             [-1, 16, 6, 6]              32\n",
      "          Dropout-22             [-1, 16, 6, 6]               0\n",
      "           Conv2d-23             [-1, 16, 8, 8]             256\n",
      "             ReLU-24             [-1, 16, 8, 8]               0\n",
      "      BatchNorm2d-25             [-1, 16, 8, 8]              32\n",
      "          Dropout-26             [-1, 16, 8, 8]               0\n",
      "        AvgPool2d-27             [-1, 16, 1, 1]               0\n",
      "           Conv2d-28             [-1, 10, 1, 1]             160\n",
      "================================================================\n",
      "Total params: 8,024\n",
      "Trainable params: 8,024\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.63\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88cb0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct=0\n",
    "  processed=0\n",
    "\n",
    "  for batch_idx, (data,target) in enumerate(pbar):\n",
    "    data,target = data.to(device), target.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred=model(data)\n",
    "\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc=f'loss={loss.item()} Batch_id ={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "  model.eval()\n",
    "  test_loss = 0;\n",
    "  correct = 0;\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data,target = data.to(device), target.to(device)\n",
    "      output=model(data)\n",
    "      test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "      test_loss, correct, len(test_loader.dataset),\n",
    "      100. * correct / len(test_loader.dataset)\n",
    "  ))\n",
    "\n",
    "  test_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b94f7fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.05267756059765816 Batch_id =468 Accuracy=92.75: 100%|██████████| 469/469 [00:14<00:00, 33.19it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0708, Accuracy: 9775/10000 (97.75%)\n",
      "\n",
      "EPOCH:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.05580747500061989 Batch_id =468 Accuracy=97.69: 100%|██████████| 469/469 [00:04<00:00, 105.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0475, Accuracy: 9849/10000 (98.49%)\n",
      "\n",
      "EPOCH:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.018529877066612244 Batch_id =468 Accuracy=98.02: 100%|██████████| 469/469 [00:04<00:00, 109.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0402, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "EPOCH:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.038204170763492584 Batch_id =468 Accuracy=98.28: 100%|██████████| 469/469 [00:04<00:00, 108.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0382, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "EPOCH:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.03553943336009979 Batch_id =468 Accuracy=98.37: 100%|██████████| 469/469 [00:04<00:00, 110.87it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0418, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "EPOCH:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04138034209609032 Batch_id =468 Accuracy=98.57: 100%|██████████| 469/469 [00:04<00:00, 109.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0336, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "EPOCH:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0751088410615921 Batch_id =468 Accuracy=98.96: 100%|██████████| 469/469 [00:04<00:00, 111.73it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 9926/10000 (99.26%)\n",
      "\n",
      "EPOCH:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.004982346203178167 Batch_id =468 Accuracy=99.11: 100%|██████████| 469/469 [00:04<00:00, 109.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 9937/10000 (99.37%)\n",
      "\n",
      "EPOCH:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.013883977197110653 Batch_id =468 Accuracy=99.14: 100%|██████████| 469/469 [00:04<00:00, 108.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 9941/10000 (99.41%)\n",
      "\n",
      "EPOCH:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.012470371089875698 Batch_id =468 Accuracy=99.20: 100%|██████████| 469/469 [00:04<00:00, 108.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 9935/10000 (99.35%)\n",
      "\n",
      "EPOCH:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02267826348543167 Batch_id =468 Accuracy=99.19: 100%|██████████| 469/469 [00:04<00:00, 111.12it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 9939/10000 (99.39%)\n",
      "\n",
      "EPOCH:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.015917159616947174 Batch_id =468 Accuracy=99.22: 100%|██████████| 469/469 [00:04<00:00, 108.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 9938/10000 (99.38%)\n",
      "\n",
      "EPOCH:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02195201814174652 Batch_id =468 Accuracy=99.23: 100%|██████████| 469/469 [00:04<00:00, 108.66it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 9938/10000 (99.38%)\n",
      "\n",
      "EPOCH:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.006257984321564436 Batch_id =468 Accuracy=99.30: 100%|██████████| 469/469 [00:04<00:00, 109.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 9940/10000 (99.40%)\n",
      "\n",
      "EPOCH:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.007769844960421324 Batch_id =468 Accuracy=99.22: 100%|██████████| 469/469 [00:04<00:00, 110.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 9940/10000 (99.40%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model = Net().to(device)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range (EPOCHS):\n",
    "  print(\"EPOCH: \", epoch+1)\n",
    "  train(model, device, train_loader, optimizer, epoch)\n",
    "  scheduler.step()\n",
    "  test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5b04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
