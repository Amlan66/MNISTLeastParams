{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eaab2b4",
   "metadata": {},
   "source": [
    "Model 2:\n",
    "Target\n",
    "1. Add Batch norm to increase efficiency\n",
    "2. Add GAP to reduce params in last layer\n",
    "\n",
    "Result:\n",
    "1. Parameters : 8.2k\n",
    "2. Best Train Accuracy : 99.12\n",
    "3. Best Test Accuracy : 99.09\n",
    "\n",
    "Analysis:\n",
    "1. Great model, just above 8k parameters\n",
    "2. Model is underfitting and both train and test accuracy has increased over epochs\n",
    "3. Model can be pushed further with regularization or better learning start at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2da146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9045fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac1b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eefc9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "#train_loader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "#test_loader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf5001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    #INPUT\n",
    "    self.conv1= nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.BatchNorm2d(8),\n",
    "        nn.ReLU()\n",
    "    )#output = 26\n",
    "\n",
    "    #CONV 1 BLOCK\n",
    "    self.conv2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.BatchNorm2d(8),\n",
    "        nn.ReLU()\n",
    "    )#output = 24\n",
    "\n",
    "    self.conv3 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU()\n",
    "    )#output = 22\n",
    "\n",
    "    #TRANSITION BLOCK\n",
    "    self.pool1 = nn.MaxPool2d(2,2)\n",
    "\n",
    "    self.conv4 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1,1), padding=0, bias=False),\n",
    "        nn.BatchNorm2d(8),\n",
    "        nn.ReLU()\n",
    "    )#output = 11\n",
    "\n",
    "    #CONV 2 BLOCK\n",
    "    self.conv5 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU()\n",
    "    )#output = 9\n",
    "\n",
    "    self.conv6 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=0, bias=False),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU()\n",
    "    )#output = 7\n",
    "\n",
    "    #OUTPUT BLOCK\n",
    "    self.conv7 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1,1), padding=0, bias=False),\n",
    "        nn.BatchNorm2d(10),\n",
    "        nn.ReLU()\n",
    "    )#output = 7\n",
    "\n",
    "    self.gap = nn.Sequential(\n",
    "         nn.AvgPool2d(kernel_size=7)\n",
    "    )#output = 1\n",
    "\n",
    "    #self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv3(x)\n",
    "    #x = self.dropout(x)\n",
    "    x = self.pool1(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.conv5(x)\n",
    "    x = self.conv6(x)\n",
    "    #x = self.dropout(x)\n",
    "    x = self.conv7(x)\n",
    "    x = self.gap(x)\n",
    "    x = x.view(-1,10)\n",
    "    return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26add91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.5.1)\n",
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]              72\n",
      "       BatchNorm2d-2            [-1, 8, 26, 26]              16\n",
      "              ReLU-3            [-1, 8, 26, 26]               0\n",
      "            Conv2d-4            [-1, 8, 24, 24]             576\n",
      "       BatchNorm2d-5            [-1, 8, 24, 24]              16\n",
      "              ReLU-6            [-1, 8, 24, 24]               0\n",
      "            Conv2d-7           [-1, 16, 22, 22]           1,152\n",
      "       BatchNorm2d-8           [-1, 16, 22, 22]              32\n",
      "              ReLU-9           [-1, 16, 22, 22]               0\n",
      "        MaxPool2d-10           [-1, 16, 11, 11]               0\n",
      "           Conv2d-11            [-1, 8, 11, 11]             128\n",
      "      BatchNorm2d-12            [-1, 8, 11, 11]              16\n",
      "             ReLU-13            [-1, 8, 11, 11]               0\n",
      "           Conv2d-14             [-1, 16, 9, 9]           1,152\n",
      "      BatchNorm2d-15             [-1, 16, 9, 9]              32\n",
      "             ReLU-16             [-1, 16, 9, 9]               0\n",
      "           Conv2d-17             [-1, 32, 7, 7]           4,608\n",
      "      BatchNorm2d-18             [-1, 32, 7, 7]              64\n",
      "             ReLU-19             [-1, 32, 7, 7]               0\n",
      "           Conv2d-20             [-1, 10, 7, 7]             320\n",
      "      BatchNorm2d-21             [-1, 10, 7, 7]              20\n",
      "             ReLU-22             [-1, 10, 7, 7]               0\n",
      "        AvgPool2d-23             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 8,204\n",
      "Trainable params: 8,204\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.52\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85f273ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct=0\n",
    "  processed=0\n",
    "\n",
    "  for batch_idx, (data,target) in enumerate(pbar):\n",
    "    data,target = data.to(device), target.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred=model(data)\n",
    "\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc=f'loss={loss.item()} Batch_id ={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "  model.eval()\n",
    "  test_loss = 0;\n",
    "  correct = 0;\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data,target = data.to(device), target.to(device)\n",
    "      output=model(data)\n",
    "      test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "      test_loss, correct, len(test_loader.dataset),\n",
    "      100. * correct / len(test_loader.dataset)\n",
    "  ))\n",
    "\n",
    "  test_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b34e2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.25584545731544495 Batch_id =468 Accuracy=86.77: 100%|██████████| 469/469 [00:04<00:00, 107.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2452, Accuracy: 9616/10000 (96.16%)\n",
      "\n",
      "EPOCH:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.12266247719526291 Batch_id =468 Accuracy=97.05: 100%|██████████| 469/469 [00:04<00:00, 110.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1143, Accuracy: 9802/10000 (98.02%)\n",
      "\n",
      "EPOCH:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.1803968995809555 Batch_id =468 Accuracy=97.80: 100%|██████████| 469/469 [00:04<00:00, 110.66it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0967, Accuracy: 9815/10000 (98.15%)\n",
      "\n",
      "EPOCH:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.07428574562072754 Batch_id =468 Accuracy=98.19: 100%|██████████| 469/469 [00:04<00:00, 108.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0805, Accuracy: 9839/10000 (98.39%)\n",
      "\n",
      "EPOCH:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0607139877974987 Batch_id =468 Accuracy=98.41: 100%|██████████| 469/469 [00:04<00:00, 100.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0728, Accuracy: 9833/10000 (98.33%)\n",
      "\n",
      "EPOCH:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.12083827704191208 Batch_id =468 Accuracy=98.57: 100%|██████████| 469/469 [00:04<00:00, 108.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0543, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "EPOCH:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.035741548985242844 Batch_id =468 Accuracy=98.72: 100%|██████████| 469/469 [00:04<00:00, 106.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0553, Accuracy: 9875/10000 (98.75%)\n",
      "\n",
      "EPOCH:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.08134206384420395 Batch_id =468 Accuracy=98.77: 100%|██████████| 469/469 [00:04<00:00, 105.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0558, Accuracy: 9856/10000 (98.56%)\n",
      "\n",
      "EPOCH:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02947012335062027 Batch_id =468 Accuracy=98.81: 100%|██████████| 469/469 [00:04<00:00, 106.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0528, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "EPOCH:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02343722991645336 Batch_id =468 Accuracy=98.90: 100%|██████████| 469/469 [00:04<00:00, 107.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0441, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "EPOCH:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02757439576089382 Batch_id =468 Accuracy=98.95: 100%|██████████| 469/469 [00:04<00:00, 106.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0396, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "EPOCH:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.032595787197351456 Batch_id =468 Accuracy=99.00: 100%|██████████| 469/469 [00:04<00:00, 106.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0414, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "EPOCH:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04581087827682495 Batch_id =468 Accuracy=98.98: 100%|██████████| 469/469 [00:04<00:00, 105.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0380, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "EPOCH:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02119535394012928 Batch_id =468 Accuracy=99.07: 100%|██████████| 469/469 [00:04<00:00, 103.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0369, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "EPOCH:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.054779887199401855 Batch_id =468 Accuracy=99.12: 100%|██████████| 469/469 [00:04<00:00, 106.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0401, Accuracy: 9897/10000 (98.97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range (EPOCHS):\n",
    "  print(\"EPOCH: \", epoch+1)\n",
    "  train(model, device, train_loader, optimizer, epoch)\n",
    "  test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66549590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
